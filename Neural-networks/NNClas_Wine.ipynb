{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A TUTORIAL ON NEURAL NETWORK CLASSIFICATION USING KERAS AND TENSORFLOW\n",
    "\n",
    "by Sebastian T. Glavind, August, 2020\n",
    "\n",
    "# Introduction\n",
    "\n",
    "In this tutorial, we will consider how to define, train, and predict with a simple feed-forward neural network model using keras and tensorflow. First, we will consider how to use neural networks for multi-class classification. Second, we will see how to choose the hyperparameters using random search cross-validation. Note that random search is found to be superior to grid search when the model contains many hyperparameters. The interested reader is referred to the prominent textbook of Goodfellow et al. (2016) for an introduction to neural networks, and Geron (2019) for an excellent guide on their implementation.\n",
    "\n",
    "We will consider a small data set in the tutorial, i.e. the Wine recognition data set, so that training can be performed on a standard computer, thus regularization becomes extra important! In this regard, we will consider drop-out regularization.\n",
    "\n",
    "***\n",
    "I. Goodfellow, Y. Bengio, and A. Courville, Deep Learning. MIT Press, 2016, http://www.deeplearningbook.org.\n",
    "\n",
    "A. Geron, Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow: Concepts, tools, and techniques to build intelligent systems. Oâ€™Reilly Media, 2019.\n",
    "***\n",
    "\n",
    "# Prelude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as ss \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_wine\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "import sklearn.compose\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow 2.1\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras.layers import Input, InputLayer, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class classification with neural network\n",
    "\n",
    "\n",
    "## Data set\n",
    "\n",
    "In this tutorial, we will consider the Wine recognition data set, see below, which ships with `scikit-learn`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "WineData = load_wine()\n",
    "print(WineData['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples in each class [59 71 48]\n"
     ]
    }
   ],
   "source": [
    "Xraw, yraw = WineData['data'], WineData['target']\n",
    "nTarget = np.array([sum(yraw==0), sum(yraw==1), sum(yraw==2)])\n",
    "print('Samples in each class', nTarget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple random over-sampling (Bootstrapping) to manage class-imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xboost = list()\n",
    "yboost = list()\n",
    "for i in range(len(nTarget)):\n",
    "    index_i = np.where( yraw==i )[0]\n",
    "    X_i_boost = Xraw[index_i,:]\n",
    "    y_i_boost = yraw[index_i]\n",
    "    \n",
    "    if nTarget[i] < max(nTarget):\n",
    "        index_i_boost = sklearn.utils.resample(index_i, replace=True, n_samples=max(nTarget)-nTarget[i],\n",
    "                                              random_state=123)\n",
    "        X_i_boost = np.vstack([ X_i_boost, Xraw[index_i_boost,:] ])\n",
    "        y_i_boost = np.concatenate([ y_i_boost, yraw[index_i_boost] ]) \n",
    "    \n",
    "    Xboost.append(X_i_boost)\n",
    "    yboost.append(y_i_boost)\n",
    "\n",
    "Xboost = np.vstack(Xboost)\n",
    "yboost = np.concatenate(yboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = sklearn.model_selection.train_test_split(Xboost, yboost, stratify=yboost, \n",
    "                                                                        train_size=.8, shuffle=True, \n",
    "                                                                        random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling of inputs according to scale of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(Xtrain)\n",
    "sXtrain = scaler.transform(Xtrain)\n",
    "sXtest = scaler.transform(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN model\n",
    "\n",
    "### Model definition\n",
    "\n",
    "In this section, we will consider a neural network with two hidden layers of 32 units each and regularize the network training using drop-out. Other kinds of regularization are e.g. early stopping and batch normalization (commented out below), see e.g. Goodfellow et al. (2016) for a reference.\n",
    "\n",
    "***\n",
    "I. Goodfellow, Y. Bengio, and A. Courville, Deep Learning. MIT Press, 2016, http://www.deeplearningbook.org.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout (Dropout)            (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 275\n",
      "Trainable params: 275\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_model = keras.models.Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(Input(shape=(sXtrain.shape[1])))\n",
    "# NN_model.add(Flatten(input_shape=[Xtrain.shape[1]]))\n",
    "# NN_model.add(InputLayer(input_shape=Xtrain.shape[1]))\n",
    "NN_model.add(Dropout(.2))\n",
    "# NN_model.add(BatchNormalization())\n",
    "\n",
    "# The Hidden Layers :\n",
    "for layer in range(1):\n",
    "        NN_model.add(Dense(16, kernel_initializer='he_normal',activation='relu'))\n",
    "        NN_model.add(Dropout(.5))\n",
    "#         NN_model.add(BatchNormalization())\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(Dense(3, kernel_initializer='he_normal',activation='softmax'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "# checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "# callbacks_list = [checkpoint]\n",
    "# mcp = ModelCheckpoint(\"NNRreg_singleOut.hd5\", save_best_only=True, period=5)\n",
    "# csv = CSVLogger(\"NNRreg_singleOut.csv\")\n",
    "# es = EarlyStopping(patience=10, verbose=1, restore_best_weights=True)\n",
    "# lr = ReduceLROnPlateau(patience=10, verbose=1)\n",
    "callbacks_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 170 samples\n",
      "Epoch 1/200\n",
      "170/170 [==============================] - 0s 3ms/sample - loss: 1.8790 - accuracy: 0.3529\n",
      "Epoch 2/200\n",
      "170/170 [==============================] - 0s 383us/sample - loss: 1.5838 - accuracy: 0.3706\n",
      "Epoch 3/200\n",
      "170/170 [==============================] - 0s 391us/sample - loss: 1.4424 - accuracy: 0.4353\n",
      "Epoch 4/200\n",
      "170/170 [==============================] - 0s 323us/sample - loss: 1.2679 - accuracy: 0.5353\n",
      "Epoch 5/200\n",
      "170/170 [==============================] - 0s 325us/sample - loss: 1.2841 - accuracy: 0.5176\n",
      "Epoch 6/200\n",
      "170/170 [==============================] - 0s 348us/sample - loss: 1.1921 - accuracy: 0.5059\n",
      "Epoch 7/200\n",
      "170/170 [==============================] - 0s 241us/sample - loss: 1.0270 - accuracy: 0.6118\n",
      "Epoch 8/200\n",
      "170/170 [==============================] - 0s 265us/sample - loss: 0.8698 - accuracy: 0.6176\n",
      "Epoch 9/200\n",
      "170/170 [==============================] - 0s 291us/sample - loss: 0.8546 - accuracy: 0.7059\n",
      "Epoch 10/200\n",
      "170/170 [==============================] - 0s 321us/sample - loss: 0.7859 - accuracy: 0.6765\n",
      "Epoch 11/200\n",
      "170/170 [==============================] - 0s 368us/sample - loss: 0.7429 - accuracy: 0.7235\n",
      "Epoch 12/200\n",
      "170/170 [==============================] - 0s 323us/sample - loss: 0.7056 - accuracy: 0.7118\n",
      "Epoch 13/200\n",
      "170/170 [==============================] - 0s 358us/sample - loss: 0.8289 - accuracy: 0.7235\n",
      "Epoch 14/200\n",
      "170/170 [==============================] - 0s 364us/sample - loss: 0.7901 - accuracy: 0.6765\n",
      "Epoch 15/200\n",
      "170/170 [==============================] - 0s 375us/sample - loss: 0.7122 - accuracy: 0.7176\n",
      "Epoch 16/200\n",
      "170/170 [==============================] - 0s 360us/sample - loss: 0.6030 - accuracy: 0.7706\n",
      "Epoch 17/200\n",
      "170/170 [==============================] - 0s 351us/sample - loss: 0.5983 - accuracy: 0.7294\n",
      "Epoch 18/200\n",
      "170/170 [==============================] - 0s 269us/sample - loss: 0.5170 - accuracy: 0.7882\n",
      "Epoch 19/200\n",
      "170/170 [==============================] - 0s 270us/sample - loss: 0.4392 - accuracy: 0.8412\n",
      "Epoch 20/200\n",
      "170/170 [==============================] - 0s 248us/sample - loss: 0.6929 - accuracy: 0.7294\n",
      "Epoch 21/200\n",
      "170/170 [==============================] - 0s 379us/sample - loss: 0.6022 - accuracy: 0.8000\n",
      "Epoch 22/200\n",
      "170/170 [==============================] - 0s 334us/sample - loss: 0.5174 - accuracy: 0.8059\n",
      "Epoch 23/200\n",
      "170/170 [==============================] - 0s 369us/sample - loss: 0.5415 - accuracy: 0.8000\n",
      "Epoch 24/200\n",
      "170/170 [==============================] - 0s 318us/sample - loss: 0.3952 - accuracy: 0.8588\n",
      "Epoch 25/200\n",
      "170/170 [==============================] - 0s 325us/sample - loss: 0.4675 - accuracy: 0.8059\n",
      "Epoch 26/200\n",
      "170/170 [==============================] - 0s 350us/sample - loss: 0.5041 - accuracy: 0.7882\n",
      "Epoch 27/200\n",
      "170/170 [==============================] - 0s 314us/sample - loss: 0.3924 - accuracy: 0.8353\n",
      "Epoch 28/200\n",
      "170/170 [==============================] - 0s 299us/sample - loss: 0.4067 - accuracy: 0.8412\n",
      "Epoch 29/200\n",
      "170/170 [==============================] - 0s 239us/sample - loss: 0.3852 - accuracy: 0.8529\n",
      "Epoch 30/200\n",
      "170/170 [==============================] - 0s 322us/sample - loss: 0.5157 - accuracy: 0.8176\n",
      "Epoch 31/200\n",
      "170/170 [==============================] - 0s 309us/sample - loss: 0.4266 - accuracy: 0.8294\n",
      "Epoch 32/200\n",
      "170/170 [==============================] - 0s 273us/sample - loss: 0.4348 - accuracy: 0.8294\n",
      "Epoch 33/200\n",
      "170/170 [==============================] - 0s 344us/sample - loss: 0.3579 - accuracy: 0.8529\n",
      "Epoch 34/200\n",
      "170/170 [==============================] - 0s 363us/sample - loss: 0.3908 - accuracy: 0.8471\n",
      "Epoch 35/200\n",
      "170/170 [==============================] - 0s 350us/sample - loss: 0.3931 - accuracy: 0.8118\n",
      "Epoch 36/200\n",
      "170/170 [==============================] - 0s 281us/sample - loss: 0.3418 - accuracy: 0.8588\n",
      "Epoch 37/200\n",
      "170/170 [==============================] - 0s 251us/sample - loss: 0.3462 - accuracy: 0.8588\n",
      "Epoch 38/200\n",
      "170/170 [==============================] - 0s 269us/sample - loss: 0.3335 - accuracy: 0.8706\n",
      "Epoch 39/200\n",
      "170/170 [==============================] - 0s 331us/sample - loss: 0.2983 - accuracy: 0.8647\n",
      "Epoch 40/200\n",
      "170/170 [==============================] - 0s 299us/sample - loss: 0.3450 - accuracy: 0.8765\n",
      "Epoch 41/200\n",
      "170/170 [==============================] - 0s 354us/sample - loss: 0.3276 - accuracy: 0.8765\n",
      "Epoch 42/200\n",
      "170/170 [==============================] - 0s 368us/sample - loss: 0.3165 - accuracy: 0.9000\n",
      "Epoch 43/200\n",
      "170/170 [==============================] - 0s 229us/sample - loss: 0.3325 - accuracy: 0.8765\n",
      "Epoch 44/200\n",
      "170/170 [==============================] - 0s 310us/sample - loss: 0.2680 - accuracy: 0.9059\n",
      "Epoch 45/200\n",
      "170/170 [==============================] - 0s 311us/sample - loss: 0.2783 - accuracy: 0.8647\n",
      "Epoch 46/200\n",
      "170/170 [==============================] - 0s 342us/sample - loss: 0.2841 - accuracy: 0.8824\n",
      "Epoch 47/200\n",
      "170/170 [==============================] - 0s 313us/sample - loss: 0.2466 - accuracy: 0.8824\n",
      "Epoch 48/200\n",
      "170/170 [==============================] - 0s 319us/sample - loss: 0.3410 - accuracy: 0.8588\n",
      "Epoch 49/200\n",
      "170/170 [==============================] - 0s 369us/sample - loss: 0.2240 - accuracy: 0.9000\n",
      "Epoch 50/200\n",
      "170/170 [==============================] - 0s 376us/sample - loss: 0.3312 - accuracy: 0.8353\n",
      "Epoch 51/200\n",
      "170/170 [==============================] - 0s 354us/sample - loss: 0.2577 - accuracy: 0.9000\n",
      "Epoch 52/200\n",
      "170/170 [==============================] - 0s 354us/sample - loss: 0.3063 - accuracy: 0.8765\n",
      "Epoch 53/200\n",
      "170/170 [==============================] - 0s 267us/sample - loss: 0.3232 - accuracy: 0.8765\n",
      "Epoch 54/200\n",
      "170/170 [==============================] - 0s 227us/sample - loss: 0.3042 - accuracy: 0.8941\n",
      "Epoch 55/200\n",
      "170/170 [==============================] - 0s 243us/sample - loss: 0.3033 - accuracy: 0.8765\n",
      "Epoch 56/200\n",
      "170/170 [==============================] - 0s 332us/sample - loss: 0.2568 - accuracy: 0.8941\n",
      "Epoch 57/200\n",
      "170/170 [==============================] - 0s 341us/sample - loss: 0.3087 - accuracy: 0.8588\n",
      "Epoch 58/200\n",
      "170/170 [==============================] - 0s 358us/sample - loss: 0.3141 - accuracy: 0.8941\n",
      "Epoch 59/200\n",
      "170/170 [==============================] - 0s 366us/sample - loss: 0.2732 - accuracy: 0.8882\n",
      "Epoch 60/200\n",
      "170/170 [==============================] - 0s 380us/sample - loss: 0.2686 - accuracy: 0.8824\n",
      "Epoch 61/200\n",
      "170/170 [==============================] - 0s 304us/sample - loss: 0.3038 - accuracy: 0.8706\n",
      "Epoch 62/200\n",
      "170/170 [==============================] - 0s 379us/sample - loss: 0.3072 - accuracy: 0.8471\n",
      "Epoch 63/200\n",
      "170/170 [==============================] - 0s 298us/sample - loss: 0.2681 - accuracy: 0.8882\n",
      "Epoch 64/200\n",
      "170/170 [==============================] - 0s 315us/sample - loss: 0.2741 - accuracy: 0.8824\n",
      "Epoch 65/200\n",
      "170/170 [==============================] - 0s 290us/sample - loss: 0.3004 - accuracy: 0.8824\n",
      "Epoch 66/200\n",
      "170/170 [==============================] - 0s 385us/sample - loss: 0.1674 - accuracy: 0.9647\n",
      "Epoch 67/200\n",
      "170/170 [==============================] - 0s 378us/sample - loss: 0.2341 - accuracy: 0.9118\n",
      "Epoch 68/200\n",
      "170/170 [==============================] - 0s 322us/sample - loss: 0.3093 - accuracy: 0.8529\n",
      "Epoch 69/200\n",
      "170/170 [==============================] - 0s 258us/sample - loss: 0.2905 - accuracy: 0.9059\n",
      "Epoch 70/200\n",
      "170/170 [==============================] - 0s 334us/sample - loss: 0.2496 - accuracy: 0.8941\n",
      "Epoch 71/200\n",
      "170/170 [==============================] - 0s 357us/sample - loss: 0.1758 - accuracy: 0.9176\n",
      "Epoch 72/200\n",
      "170/170 [==============================] - 0s 375us/sample - loss: 0.2220 - accuracy: 0.9118\n",
      "Epoch 73/200\n",
      "170/170 [==============================] - 0s 335us/sample - loss: 0.2815 - accuracy: 0.9000\n",
      "Epoch 74/200\n",
      "170/170 [==============================] - 0s 366us/sample - loss: 0.1791 - accuracy: 0.9235\n",
      "Epoch 75/200\n",
      "170/170 [==============================] - 0s 374us/sample - loss: 0.1820 - accuracy: 0.9176\n",
      "Epoch 76/200\n",
      "170/170 [==============================] - 0s 332us/sample - loss: 0.2574 - accuracy: 0.8941\n",
      "Epoch 77/200\n",
      "170/170 [==============================] - 0s 322us/sample - loss: 0.2809 - accuracy: 0.8647\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 0s 386us/sample - loss: 0.2587 - accuracy: 0.9000\n",
      "Epoch 79/200\n",
      "170/170 [==============================] - 0s 348us/sample - loss: 0.2163 - accuracy: 0.9059\n",
      "Epoch 80/200\n",
      "170/170 [==============================] - 0s 361us/sample - loss: 0.2326 - accuracy: 0.9235\n",
      "Epoch 81/200\n",
      "170/170 [==============================] - 0s 380us/sample - loss: 0.2021 - accuracy: 0.9059\n",
      "Epoch 82/200\n",
      "170/170 [==============================] - 0s 368us/sample - loss: 0.1919 - accuracy: 0.9294\n",
      "Epoch 83/200\n",
      "170/170 [==============================] - 0s 309us/sample - loss: 0.1918 - accuracy: 0.9412\n",
      "Epoch 84/200\n",
      "170/170 [==============================] - 0s 258us/sample - loss: 0.2914 - accuracy: 0.8706\n",
      "Epoch 85/200\n",
      "170/170 [==============================] - 0s 355us/sample - loss: 0.2218 - accuracy: 0.9176\n",
      "Epoch 86/200\n",
      "170/170 [==============================] - 0s 351us/sample - loss: 0.2185 - accuracy: 0.8941\n",
      "Epoch 87/200\n",
      "170/170 [==============================] - 0s 380us/sample - loss: 0.1876 - accuracy: 0.9235\n",
      "Epoch 88/200\n",
      "170/170 [==============================] - 0s 380us/sample - loss: 0.2309 - accuracy: 0.8941\n",
      "Epoch 89/200\n",
      "170/170 [==============================] - 0s 375us/sample - loss: 0.2224 - accuracy: 0.9118\n",
      "Epoch 90/200\n",
      "170/170 [==============================] - 0s 363us/sample - loss: 0.1639 - accuracy: 0.9353\n",
      "Epoch 91/200\n",
      "170/170 [==============================] - 0s 361us/sample - loss: 0.2005 - accuracy: 0.9000\n",
      "Epoch 92/200\n",
      "170/170 [==============================] - 0s 366us/sample - loss: 0.2160 - accuracy: 0.9000\n",
      "Epoch 93/200\n",
      "170/170 [==============================] - 0s 332us/sample - loss: 0.2277 - accuracy: 0.9118\n",
      "Epoch 94/200\n",
      "170/170 [==============================] - 0s 369us/sample - loss: 0.1593 - accuracy: 0.9471\n",
      "Epoch 95/200\n",
      "170/170 [==============================] - 0s 351us/sample - loss: 0.1975 - accuracy: 0.8941\n",
      "Epoch 96/200\n",
      "170/170 [==============================] - 0s 359us/sample - loss: 0.2185 - accuracy: 0.9000\n",
      "Epoch 97/200\n",
      "170/170 [==============================] - 0s 307us/sample - loss: 0.1841 - accuracy: 0.9235\n",
      "Epoch 98/200\n",
      "170/170 [==============================] - 0s 312us/sample - loss: 0.1936 - accuracy: 0.8824\n",
      "Epoch 99/200\n",
      "170/170 [==============================] - 0s 297us/sample - loss: 0.2368 - accuracy: 0.8882\n",
      "Epoch 100/200\n",
      "170/170 [==============================] - 0s 373us/sample - loss: 0.2479 - accuracy: 0.8941\n",
      "Epoch 101/200\n",
      "170/170 [==============================] - 0s 372us/sample - loss: 0.1264 - accuracy: 0.9529\n",
      "Epoch 102/200\n",
      "170/170 [==============================] - 0s 414us/sample - loss: 0.1878 - accuracy: 0.9176\n",
      "Epoch 103/200\n",
      "170/170 [==============================] - 0s 318us/sample - loss: 0.2045 - accuracy: 0.8941\n",
      "Epoch 104/200\n",
      "170/170 [==============================] - 0s 382us/sample - loss: 0.2520 - accuracy: 0.8941\n",
      "Epoch 105/200\n",
      "170/170 [==============================] - 0s 361us/sample - loss: 0.2616 - accuracy: 0.8882\n",
      "Epoch 106/200\n",
      "170/170 [==============================] - 0s 361us/sample - loss: 0.2019 - accuracy: 0.9118\n",
      "Epoch 107/200\n",
      "170/170 [==============================] - 0s 323us/sample - loss: 0.1961 - accuracy: 0.9118\n",
      "Epoch 108/200\n",
      "170/170 [==============================] - 0s 304us/sample - loss: 0.2169 - accuracy: 0.9000\n",
      "Epoch 109/200\n",
      "170/170 [==============================] - 0s 303us/sample - loss: 0.1628 - accuracy: 0.9294\n",
      "Epoch 110/200\n",
      "170/170 [==============================] - 0s 374us/sample - loss: 0.2209 - accuracy: 0.9059\n",
      "Epoch 111/200\n",
      "170/170 [==============================] - 0s 330us/sample - loss: 0.2258 - accuracy: 0.8882\n",
      "Epoch 112/200\n",
      "170/170 [==============================] - 0s 264us/sample - loss: 0.1756 - accuracy: 0.9353\n",
      "Epoch 113/200\n",
      "170/170 [==============================] - 0s 380us/sample - loss: 0.1701 - accuracy: 0.9353\n",
      "Epoch 114/200\n",
      "170/170 [==============================] - 0s 263us/sample - loss: 0.2247 - accuracy: 0.9235\n",
      "Epoch 115/200\n",
      "170/170 [==============================] - 0s 222us/sample - loss: 0.1832 - accuracy: 0.9059\n",
      "Epoch 116/200\n",
      "170/170 [==============================] - 0s 388us/sample - loss: 0.2293 - accuracy: 0.9059\n",
      "Epoch 117/200\n",
      "170/170 [==============================] - 0s 363us/sample - loss: 0.1836 - accuracy: 0.9353\n",
      "Epoch 118/200\n",
      "170/170 [==============================] - 0s 313us/sample - loss: 0.2731 - accuracy: 0.9118\n",
      "Epoch 119/200\n",
      "170/170 [==============================] - 0s 375us/sample - loss: 0.2512 - accuracy: 0.8824\n",
      "Epoch 120/200\n",
      "170/170 [==============================] - 0s 359us/sample - loss: 0.1960 - accuracy: 0.9118\n",
      "Epoch 121/200\n",
      "170/170 [==============================] - 0s 373us/sample - loss: 0.1555 - accuracy: 0.9471\n",
      "Epoch 122/200\n",
      "170/170 [==============================] - 0s 362us/sample - loss: 0.2015 - accuracy: 0.9176\n",
      "Epoch 123/200\n",
      "170/170 [==============================] - 0s 357us/sample - loss: 0.1762 - accuracy: 0.9471\n",
      "Epoch 124/200\n",
      "170/170 [==============================] - 0s 376us/sample - loss: 0.1665 - accuracy: 0.9471\n",
      "Epoch 125/200\n",
      "170/170 [==============================] - 0s 334us/sample - loss: 0.1701 - accuracy: 0.9294\n",
      "Epoch 126/200\n",
      "170/170 [==============================] - 0s 326us/sample - loss: 0.1945 - accuracy: 0.9059\n",
      "Epoch 127/200\n",
      "170/170 [==============================] - 0s 305us/sample - loss: 0.1974 - accuracy: 0.9118\n",
      "Epoch 128/200\n",
      "170/170 [==============================] - 0s 375us/sample - loss: 0.2161 - accuracy: 0.9059\n",
      "Epoch 129/200\n",
      "170/170 [==============================] - 0s 331us/sample - loss: 0.1964 - accuracy: 0.9059\n",
      "Epoch 130/200\n",
      "170/170 [==============================] - 0s 331us/sample - loss: 0.1522 - accuracy: 0.9353\n",
      "Epoch 131/200\n",
      "170/170 [==============================] - 0s 366us/sample - loss: 0.1697 - accuracy: 0.9353\n",
      "Epoch 132/200\n",
      "170/170 [==============================] - 0s 377us/sample - loss: 0.1545 - accuracy: 0.9176\n",
      "Epoch 133/200\n",
      "170/170 [==============================] - 0s 376us/sample - loss: 0.2202 - accuracy: 0.9000\n",
      "Epoch 134/200\n",
      "170/170 [==============================] - 0s 360us/sample - loss: 0.2142 - accuracy: 0.8941\n",
      "Epoch 135/200\n",
      "170/170 [==============================] - 0s 373us/sample - loss: 0.1923 - accuracy: 0.9118\n",
      "Epoch 136/200\n",
      "170/170 [==============================] - 0s 375us/sample - loss: 0.1342 - accuracy: 0.9471\n",
      "Epoch 137/200\n",
      "170/170 [==============================] - 0s 362us/sample - loss: 0.2007 - accuracy: 0.9412\n",
      "Epoch 138/200\n",
      "170/170 [==============================] - 0s 317us/sample - loss: 0.0935 - accuracy: 0.9824\n",
      "Epoch 139/200\n",
      "170/170 [==============================] - 0s 355us/sample - loss: 0.1362 - accuracy: 0.9353\n",
      "Epoch 140/200\n",
      "170/170 [==============================] - 0s 361us/sample - loss: 0.1173 - accuracy: 0.9471\n",
      "Epoch 141/200\n",
      "170/170 [==============================] - 0s 323us/sample - loss: 0.1348 - accuracy: 0.9471\n",
      "Epoch 142/200\n",
      "170/170 [==============================] - 0s 246us/sample - loss: 0.1210 - accuracy: 0.9529\n",
      "Epoch 143/200\n",
      "170/170 [==============================] - 0s 355us/sample - loss: 0.2167 - accuracy: 0.9353\n",
      "Epoch 144/200\n",
      "170/170 [==============================] - 0s 334us/sample - loss: 0.1158 - accuracy: 0.9647\n",
      "Epoch 145/200\n",
      "170/170 [==============================] - 0s 364us/sample - loss: 0.2314 - accuracy: 0.9353\n",
      "Epoch 146/200\n",
      "170/170 [==============================] - 0s 308us/sample - loss: 0.2149 - accuracy: 0.9176\n",
      "Epoch 147/200\n",
      "170/170 [==============================] - 0s 305us/sample - loss: 0.2094 - accuracy: 0.9176\n",
      "Epoch 148/200\n",
      "170/170 [==============================] - 0s 380us/sample - loss: 0.1546 - accuracy: 0.9471\n",
      "Epoch 149/200\n",
      "170/170 [==============================] - 0s 401us/sample - loss: 0.0967 - accuracy: 0.9588\n",
      "Epoch 150/200\n",
      "170/170 [==============================] - 0s 374us/sample - loss: 0.1468 - accuracy: 0.9529\n",
      "Epoch 151/200\n",
      "170/170 [==============================] - 0s 321us/sample - loss: 0.1504 - accuracy: 0.9353\n",
      "Epoch 152/200\n",
      "170/170 [==============================] - 0s 317us/sample - loss: 0.2151 - accuracy: 0.9059\n",
      "Epoch 153/200\n",
      "170/170 [==============================] - 0s 329us/sample - loss: 0.2078 - accuracy: 0.9235\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 0s 359us/sample - loss: 0.1298 - accuracy: 0.9353\n",
      "Epoch 155/200\n",
      "170/170 [==============================] - 0s 286us/sample - loss: 0.1914 - accuracy: 0.9118\n",
      "Epoch 156/200\n",
      "170/170 [==============================] - 0s 374us/sample - loss: 0.1597 - accuracy: 0.9412\n",
      "Epoch 157/200\n",
      "170/170 [==============================] - 0s 368us/sample - loss: 0.1998 - accuracy: 0.9176\n",
      "Epoch 158/200\n",
      "170/170 [==============================] - 0s 381us/sample - loss: 0.1352 - accuracy: 0.9353\n",
      "Epoch 159/200\n",
      "170/170 [==============================] - 0s 380us/sample - loss: 0.1588 - accuracy: 0.9353\n",
      "Epoch 160/200\n",
      "170/170 [==============================] - 0s 371us/sample - loss: 0.1683 - accuracy: 0.9294\n",
      "Epoch 161/200\n",
      "170/170 [==============================] - 0s 298us/sample - loss: 0.1670 - accuracy: 0.9118\n",
      "Epoch 162/200\n",
      "170/170 [==============================] - 0s 297us/sample - loss: 0.1899 - accuracy: 0.9235\n",
      "Epoch 163/200\n",
      "170/170 [==============================] - 0s 382us/sample - loss: 0.0940 - accuracy: 0.9471\n",
      "Epoch 164/200\n",
      "170/170 [==============================] - 0s 358us/sample - loss: 0.1482 - accuracy: 0.9471\n",
      "Epoch 165/200\n",
      "170/170 [==============================] - 0s 372us/sample - loss: 0.1421 - accuracy: 0.9471\n",
      "Epoch 166/200\n",
      "170/170 [==============================] - 0s 365us/sample - loss: 0.1435 - accuracy: 0.9353\n",
      "Epoch 167/200\n",
      "170/170 [==============================] - 0s 349us/sample - loss: 0.1462 - accuracy: 0.9294\n",
      "Epoch 168/200\n",
      "170/170 [==============================] - 0s 389us/sample - loss: 0.1191 - accuracy: 0.9471\n",
      "Epoch 169/200\n",
      "170/170 [==============================] - 0s 331us/sample - loss: 0.1445 - accuracy: 0.9176\n",
      "Epoch 170/200\n",
      "170/170 [==============================] - 0s 356us/sample - loss: 0.1714 - accuracy: 0.9176\n",
      "Epoch 171/200\n",
      "170/170 [==============================] - 0s 309us/sample - loss: 0.1816 - accuracy: 0.9176\n",
      "Epoch 172/200\n",
      "170/170 [==============================] - 0s 296us/sample - loss: 0.1868 - accuracy: 0.9235\n",
      "Epoch 173/200\n",
      "170/170 [==============================] - 0s 325us/sample - loss: 0.1649 - accuracy: 0.9471\n",
      "Epoch 174/200\n",
      "170/170 [==============================] - 0s 359us/sample - loss: 0.0773 - accuracy: 0.9706\n",
      "Epoch 175/200\n",
      "170/170 [==============================] - 0s 357us/sample - loss: 0.1637 - accuracy: 0.9294\n",
      "Epoch 176/200\n",
      "170/170 [==============================] - 0s 362us/sample - loss: 0.1651 - accuracy: 0.9294\n",
      "Epoch 177/200\n",
      "170/170 [==============================] - 0s 392us/sample - loss: 0.1386 - accuracy: 0.9353\n",
      "Epoch 178/200\n",
      "170/170 [==============================] - 0s 376us/sample - loss: 0.2599 - accuracy: 0.9294\n",
      "Epoch 179/200\n",
      "170/170 [==============================] - 0s 291us/sample - loss: 0.1778 - accuracy: 0.9176\n",
      "Epoch 180/200\n",
      "170/170 [==============================] - 0s 288us/sample - loss: 0.1271 - accuracy: 0.9412\n",
      "Epoch 181/200\n",
      "170/170 [==============================] - 0s 301us/sample - loss: 0.1515 - accuracy: 0.9353\n",
      "Epoch 182/200\n",
      "170/170 [==============================] - 0s 261us/sample - loss: 0.1724 - accuracy: 0.9294\n",
      "Epoch 183/200\n",
      "170/170 [==============================] - 0s 353us/sample - loss: 0.1912 - accuracy: 0.9176\n",
      "Epoch 184/200\n",
      "170/170 [==============================] - 0s 350us/sample - loss: 0.1651 - accuracy: 0.9118\n",
      "Epoch 185/200\n",
      "170/170 [==============================] - 0s 288us/sample - loss: 0.1321 - accuracy: 0.9529\n",
      "Epoch 186/200\n",
      "170/170 [==============================] - 0s 271us/sample - loss: 0.1360 - accuracy: 0.9353\n",
      "Epoch 187/200\n",
      "170/170 [==============================] - 0s 366us/sample - loss: 0.1153 - accuracy: 0.9471\n",
      "Epoch 188/200\n",
      "170/170 [==============================] - 0s 410us/sample - loss: 0.0998 - accuracy: 0.9706\n",
      "Epoch 189/200\n",
      "170/170 [==============================] - 0s 369us/sample - loss: 0.0866 - accuracy: 0.9588\n",
      "Epoch 190/200\n",
      "170/170 [==============================] - 0s 382us/sample - loss: 0.1243 - accuracy: 0.9353\n",
      "Epoch 191/200\n",
      "170/170 [==============================] - 0s 367us/sample - loss: 0.1738 - accuracy: 0.9235\n",
      "Epoch 192/200\n",
      "170/170 [==============================] - 0s 383us/sample - loss: 0.1310 - accuracy: 0.9353\n",
      "Epoch 193/200\n",
      "170/170 [==============================] - 0s 363us/sample - loss: 0.1444 - accuracy: 0.9471\n",
      "Epoch 194/200\n",
      "170/170 [==============================] - 0s 370us/sample - loss: 0.1532 - accuracy: 0.9353\n",
      "Epoch 195/200\n",
      "170/170 [==============================] - 0s 356us/sample - loss: 0.1449 - accuracy: 0.9353\n",
      "Epoch 196/200\n",
      "170/170 [==============================] - 0s 334us/sample - loss: 0.1237 - accuracy: 0.9529\n",
      "Epoch 197/200\n",
      "170/170 [==============================] - 0s 319us/sample - loss: 0.1342 - accuracy: 0.9471\n",
      "Epoch 198/200\n",
      "170/170 [==============================] - 0s 294us/sample - loss: 0.1364 - accuracy: 0.9353\n",
      "Epoch 199/200\n",
      "170/170 [==============================] - 0s 337us/sample - loss: 0.1240 - accuracy: 0.9471\n",
      "Epoch 200/200\n",
      "170/170 [==============================] - 0s 320us/sample - loss: 0.1640 - accuracy: 0.9353\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(123)\n",
    "history = NN_model.fit(sXtrain, ytrain, epochs=200, batch_size=8, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Training loss and metrics')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.axis([0, 200, 0, 1.25])\n",
    "plt.legend(['Cross-entropy', 'Accuracy'], loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 0s 451us/sample - loss: 0.0121 - accuracy: 1.0000\n",
      "\n",
      " Assessment of error: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        57\n",
      "           1       1.00      1.00      1.00        56\n",
      "           2       1.00      1.00      1.00        57\n",
      "\n",
      "    accuracy                           1.00       170\n",
      "   macro avg       1.00      1.00      1.00       170\n",
      "weighted avg       1.00      1.00      1.00       170\n",
      "\n",
      "Confusion:\n",
      "[[57  0  0]\n",
      " [ 0 56  0]\n",
      " [ 0  0 57]]\n",
      "Predictions (prob):\n",
      "[[0.    0.    1.   ]\n",
      " [0.    0.001 0.999]\n",
      " [0.005 0.995 0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.001 0.981 0.019]\n",
      " [0.    1.    0.   ]\n",
      " [1.    0.    0.   ]]\n"
     ]
    }
   ],
   "source": [
    "NN_model.evaluate(sXtrain, ytrain)\n",
    "\n",
    "print('\\n Assessment of error: \\n')\n",
    "pred_train_prob = NN_model.predict(sXtrain)\n",
    "pred_train = np.argmax(pred_train_prob, axis=1)\n",
    "print(sklearn.metrics.classification_report(ytrain,pred_train))\n",
    "print('Confusion:')\n",
    "print(sklearn.metrics.confusion_matrix(ytrain,pred_train))\n",
    "print('Predictions (prob):')\n",
    "print(np.round(pred_train_prob[1:10,:],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 147us/sample - loss: 0.0222 - accuracy: 0.9767\n",
      "\n",
      " Assessment of error: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        14\n",
      "           1       0.94      1.00      0.97        15\n",
      "           2       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           0.98        43\n",
      "   macro avg       0.98      0.98      0.98        43\n",
      "weighted avg       0.98      0.98      0.98        43\n",
      "\n",
      "Confusion:\n",
      "[[13  1  0]\n",
      " [ 0 15  0]\n",
      " [ 0  0 14]]\n",
      "Predictions (prob):\n",
      "[[0.    0.    1.   ]\n",
      " [0.    0.001 0.999]\n",
      " [0.    1.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [1.    0.    0.   ]]\n"
     ]
    }
   ],
   "source": [
    "NN_model.evaluate(sXtest, ytest);\n",
    "\n",
    "print('\\n Assessment of error: \\n')\n",
    "pred_test_prob = NN_model.predict(sXtest)\n",
    "pred_test = np.argmax(pred_test_prob, axis=1)\n",
    "print(sklearn.metrics.classification_report(ytest,pred_test))\n",
    "print('Confusion:')\n",
    "print(sklearn.metrics.confusion_matrix(ytest,pred_test))\n",
    "print('Predictions (prob):')\n",
    "print(np.round(pred_test_prob[1:10,:],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization\n",
    "\n",
    "It gets tedious to find an \"optimal\" combination of the hyperparameters by hand, so in this section, we will explore how we can automate this process.\n",
    "\n",
    "## Random search\n",
    "\n",
    "In this section, we will use the random search implementation `RandomizedSearchCV` of the `sklearn` package to select a setting for the model hyperparameters, which we will take to be the number of hidden layers and neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define a model builder function for `RandomizedSearchCV`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(n_hidden=1, n_units=16, r_dropOut_hidden=.5, input_shape=[13]):\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    # The Input Layer :\n",
    "    model.add(InputLayer(input_shape=input_shape))\n",
    "    model.add(Dropout(.2))\n",
    "#     NN_model.add(BatchNormalization())\n",
    "\n",
    "    # The Hidden Layers :\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(Dense(n_units, kernel_initializer='he_normal',activation='relu'))\n",
    "        model.add(Dropout(r_dropOut_hidden))\n",
    "#         NN_model.add(BatchNormalization())\n",
    "\n",
    "    # The Output Layer :\n",
    "    model.add(Dense(3, kernel_initializer='he_normal',activation='softmax'))\n",
    "\n",
    "    # Compile the network :\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we wrap the model for use with `sklearn` using the `KerasClassifier` function, define the search space, and perform the optimization. Note that this is a little time consuming even for this small example, and thus the optimization is pre-run, saved and loaded below (uncomment the content of the following two cells to re-run the optimization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimators = []\n",
    "# estimators.append(( 'scaler', sklearn.preprocessing.StandardScaler() ))\n",
    "# estimators.append(( 'mlp', keras.wrappers.scikit_learn.KerasClassifier(model_opt) ))\n",
    "# pipeline = Pipeline(estimators)\n",
    "\n",
    "# hyper_param = {'mlp__n_hidden': (1,2,3),\n",
    "#                'mlp__n_units': (8, 16, 32, 64, 128),\n",
    "#                'mlp__r_dropOut_hidden': (.2, .3, .4, .5)\n",
    "#               }\n",
    "\n",
    "# rsCV = RandomizedSearchCV(pipeline, hyper_param, n_iter=10, cv=5, refit=True, random_state=42)\n",
    "# rsCV.fit(Xtrain, ytrain, mlp__epochs=200, mlp__batch_size=8, mlp__callbacks=callbacks_list);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rsCV.best_params_)\n",
    "# optScaler = rsCV.best_estimator_['scaler'] # collect input scaler\n",
    "# optModel = rsCV.best_estimator_['mlp'].model # collect model\n",
    "# optModel.save('NNClas_optModel.h5')  # creates a HDF5 file 'NNClas_optModel.h5'\n",
    "# pickle.dump(optScaler, open('NNClas_scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_264\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_820 (Dropout)        (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_832 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dropout_821 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_833 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_822 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_834 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_823 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_835 (Dense)            (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 819\n",
      "Trainable params: 819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optScaler = pickle.load(open('NNClas_scaler.pkl', 'rb'))\n",
    "optModel = keras.models.load_model('NNClas_optModel.h5')\n",
    "optModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 0s 462us/sample - loss: 0.0091 - accuracy: 1.0000\n",
      "\n",
      " Assessment of error: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        57\n",
      "           1       1.00      1.00      1.00        56\n",
      "           2       1.00      1.00      1.00        57\n",
      "\n",
      "    accuracy                           1.00       170\n",
      "   macro avg       1.00      1.00      1.00       170\n",
      "weighted avg       1.00      1.00      1.00       170\n",
      "\n",
      "Confusion:\n",
      "[[57  0  0]\n",
      " [ 0 56  0]\n",
      " [ 0  0 57]]\n",
      "Predictions (prob):\n",
      "[[0.    0.    1.   ]\n",
      " [0.    0.    1.   ]\n",
      " [0.    1.    0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.012 0.974 0.014]\n",
      " [0.    1.    0.   ]\n",
      " [1.    0.    0.   ]]\n"
     ]
    }
   ],
   "source": [
    "sXtrain_opt = optScaler.transform(Xtrain) # same as sXtrain (scaler trained on full training set in both cases)\n",
    "optModel.evaluate(sXtrain_opt, ytrain)\n",
    "print('\\n Assessment of error: \\n')\n",
    "pred_train_prob_opt = optModel.predict(sXtrain_opt)\n",
    "pred_train_opt = np.argmax(pred_train_prob_opt, axis=1)\n",
    "print(sklearn.metrics.classification_report(ytrain,pred_train_opt))\n",
    "print('Confusion:')\n",
    "print(sklearn.metrics.confusion_matrix(ytrain,pred_train_opt))\n",
    "print('Predictions (prob):')\n",
    "print(np.round(pred_train_prob_opt[1:10,:],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 113us/sample - loss: 0.0108 - accuracy: 1.0000\n",
      "\n",
      " Assessment of error: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        15\n",
      "           2       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        43\n",
      "   macro avg       1.00      1.00      1.00        43\n",
      "weighted avg       1.00      1.00      1.00        43\n",
      "\n",
      "Confusion:\n",
      "[[14  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  0 14]]\n",
      "Predictions (prob):\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "sXtest_opt = optScaler.transform(Xtest) # same as sXtest (scaler trained on full training set in both cases)\n",
    "optModel.evaluate(sXtest_opt, ytest)\n",
    "print('\\n Assessment of error: \\n')\n",
    "pred_test_prob_opt = optModel.predict(sXtest_opt)\n",
    "pred_test_opt = np.argmax(pred_test_prob_opt, axis=1)\n",
    "print(sklearn.metrics.classification_report(ytest, pred_test_opt))\n",
    "print('Confusion:')\n",
    "print(sklearn.metrics.confusion_matrix(ytest ,pred_test_opt))\n",
    "print('Predictions (prob):')\n",
    "print(np.round(pred_test_prob_opt[1:10,:],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This optimized model result in a perfect performance on both the training and test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
